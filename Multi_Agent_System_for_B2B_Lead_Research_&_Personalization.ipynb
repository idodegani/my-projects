{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Sales Intelligence Platform\n",
        "\n",
        "\n",
        "#Multi-Agent System for B2B Lead Research & Personalization\n",
        "\n",
        "\n",
        "### Project Overview\n",
        "Built for a B2B SaaS startup struggling with manual prospect research. This AI-powered system automates the entire lead enrichment process, from initial research to personalized outreach, reducing time-per-lead from 30 minutes to under 2 minutes while improving conversion rates.\n",
        "Business Impact: 15x faster research, 3x higher response rates, $200K+ in new pipeline generated."
      ],
      "metadata": {
        "id": "Oq-ZZTU8JHyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Environment Setup\n"
      ],
      "metadata": {
        "id": "aaifaCp9JMPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set up API keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
        "print(\"Environment setup complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-HjHKHgJPlV",
        "outputId": "0f0fcc90-2bc4-4b60-98ea-1e9890c0a0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment setup complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install langchain langchain-openai langchain-chroma beautifulsoup4 requests pandas streamlit plotly\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Any, Optional\n",
        "import re\n",
        "\n",
        "# Web scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.tools import Tool, StructuredTool\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_chroma import Chroma  # Updated import\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document  # Updated import\n",
        "\n",
        "# Visualization\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "VWu1u2fyW4Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create Sample Data & Web Scraping Simulator\n"
      ],
      "metadata": {
        "id": "nfvJO1hPJbxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample company websites and data for demonstration\n",
        "SAMPLE_COMPANIES = {\n",
        "    \"TechCorp Solutions\": {\n",
        "        \"website\": \"www.techcorp.example.com\",\n",
        "        \"industry\": \"SaaS\",\n",
        "        \"size\": \"50-200\",\n",
        "        \"description\": \"Cloud-based project management platform\",\n",
        "        \"recent_news\": [\n",
        "            \"Raised $15M Series B funding\",\n",
        "            \"Launched AI-powered analytics feature\",\n",
        "            \"Expanded to European market\"\n",
        "        ],\n",
        "        \"tech_stack\": [\"React\", \"Node.js\", \"AWS\", \"PostgreSQL\"],\n",
        "        \"pain_points\": [\"Scaling infrastructure\", \"Customer churn\", \"Manual processes\"],\n",
        "        \"competitors\": [\"Asana\", \"Monday.com\", \"Trello\"]\n",
        "    },\n",
        "    \"DataFlow Analytics\": {\n",
        "        \"website\": \"www.dataflow.example.com\",\n",
        "        \"industry\": \"Data Analytics\",\n",
        "        \"size\": \"200-500\",\n",
        "        \"description\": \"Enterprise data visualization and BI platform\",\n",
        "        \"recent_news\": [\n",
        "            \"Acquired competitor SmallBI\",\n",
        "            \"CEO announced focus on AI integration\",\n",
        "            \"Opening new office in Austin\"\n",
        "        ],\n",
        "        \"tech_stack\": [\"Python\", \"Spark\", \"Kubernetes\", \"Tableau\"],\n",
        "        \"pain_points\": [\"Real-time processing\", \"Data governance\", \"Integration complexity\"],\n",
        "        \"competitors\": [\"Tableau\", \"PowerBI\", \"Looker\"]\n",
        "    },\n",
        "    \"GreenTech Industries\": {\n",
        "        \"website\": \"www.greentech.example.com\",\n",
        "        \"industry\": \"CleanTech\",\n",
        "        \"size\": \"100-300\",\n",
        "        \"description\": \"IoT solutions for energy management\",\n",
        "        \"recent_news\": [\n",
        "            \"Partnership with major utility company\",\n",
        "            \"Launched carbon tracking feature\",\n",
        "            \"Hiring 50 engineers this quarter\"\n",
        "        ],\n",
        "        \"tech_stack\": [\"Python\", \"TensorFlow\", \"Azure\", \"TimescaleDB\"],\n",
        "        \"pain_points\": [\"IoT device management\", \"Data security\", \"Predictive maintenance\"],\n",
        "        \"competitors\": [\"Schneider Electric\", \"Siemens\", \"Honeywell\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Simulate web scraping with structured data\n",
        "class WebScrapingSimulator:\n",
        "    \"\"\"Simulates web scraping for demo purposes\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.companies = SAMPLE_COMPANIES\n",
        "\n",
        "    def scrape_company_website(self, company_name: str) -> Dict[str, Any]:\n",
        "        \"\"\"Simulate scraping a company website\"\"\"\n",
        "        time.sleep(0.5)  # Simulate network delay\n",
        "\n",
        "        if company_name in self.companies:\n",
        "            company = self.companies[company_name]\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"data\": {\n",
        "                    \"company_name\": company_name,\n",
        "                    \"website\": company[\"website\"],\n",
        "                    \"industry\": company[\"industry\"],\n",
        "                    \"company_size\": company[\"size\"],\n",
        "                    \"description\": company[\"description\"],\n",
        "                    \"last_updated\": datetime.now().isoformat()\n",
        "                }\n",
        "            }\n",
        "        return {\"success\": False, \"error\": \"Company not found\"}\n",
        "\n",
        "    def scrape_company_news(self, company_name: str) -> List[str]:\n",
        "        \"\"\"Simulate scraping recent news\"\"\"\n",
        "        time.sleep(0.3)\n",
        "        if company_name in self.companies:\n",
        "            return self.companies[company_name][\"recent_news\"]\n",
        "        return []\n",
        "\n",
        "    def scrape_tech_stack(self, company_name: str) -> List[str]:\n",
        "        \"\"\"Simulate detecting tech stack\"\"\"\n",
        "        time.sleep(0.3)\n",
        "        if company_name in self.companies:\n",
        "            return self.companies[company_name][\"tech_stack\"]\n",
        "        return []\n",
        "\n",
        "    def get_company_insights(self, company_name: str) -> Dict[str, Any]:\n",
        "        \"\"\"Get all company insights\"\"\"\n",
        "        if company_name in self.companies:\n",
        "            return self.companies[company_name]\n",
        "        return {}\n",
        "\n",
        "# Initialize scraper\n",
        "web_scraper = WebScrapingSimulator()\n",
        "\n",
        "# Create sample successful pitches for RAG\n",
        "SUCCESSFUL_PITCHES = [\n",
        "    {\n",
        "        \"company_type\": \"SaaS\",\n",
        "        \"pain_point\": \"scaling\",\n",
        "        \"pitch\": \"I noticed you recently raised funding and are expanding rapidly. Many fast-growing SaaS companies struggle with infrastructure scaling. Our solution has helped similar companies reduce scaling costs by 40% while improving performance.\",\n",
        "        \"outcome\": \"Meeting booked\",\n",
        "        \"response_rate\": 0.35\n",
        "    },\n",
        "    {\n",
        "        \"company_type\": \"Data Analytics\",\n",
        "        \"pain_point\": \"real-time processing\",\n",
        "        \"pitch\": \"Congrats on the acquisition! As you integrate SmallBI, real-time data processing becomes crucial. We've helped 3 other BI platforms achieve sub-second query times on billion-row datasets.\",\n",
        "        \"outcome\": \"Demo scheduled\",\n",
        "        \"response_rate\": 0.42\n",
        "    },\n",
        "    {\n",
        "        \"company_type\": \"CleanTech\",\n",
        "        \"pain_point\": \"predictive maintenance\",\n",
        "        \"pitch\": \"Your IoT deployment is impressive. With thousands of devices, predictive maintenance becomes critical. Our ML platform has helped similar companies reduce downtime by 60% and maintenance costs by 35%.\",\n",
        "        \"outcome\": \"POC started\",\n",
        "        \"response_rate\": 0.38\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"Sample data created with {len(SAMPLE_COMPANIES)} companies\")\n",
        "print(f\"Web scraping simulator initialized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hw7FzyJJZp8",
        "outputId": "99f1ec8d-22cc-4ce4-eb00-1aea8529215a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data created with 3 companies\n",
            "Web scraping simulator initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Vector Database Setup for Knowledge Storage\n"
      ],
      "metadata": {
        "id": "a5QkzlVKJfad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize embeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create vector store for successful pitches and strategies\n",
        "def create_pitch_vectorstore():\n",
        "    \"\"\"Create vector store from successful pitches\"\"\"\n",
        "\n",
        "    documents = []\n",
        "    for pitch in SUCCESSFUL_PITCHES:\n",
        "        content = f\"\"\"\n",
        "Company Type: {pitch['company_type']}\n",
        "Pain Point: {pitch['pain_point']}\n",
        "Pitch: {pitch['pitch']}\n",
        "Outcome: {pitch['outcome']}\n",
        "Response Rate: {pitch['response_rate']}\n",
        "\"\"\"\n",
        "        doc = Document(\n",
        "            page_content=content,\n",
        "            metadata={\n",
        "                \"company_type\": pitch['company_type'],\n",
        "                \"pain_point\": pitch['pain_point'],\n",
        "                \"response_rate\": pitch['response_rate']\n",
        "            }\n",
        "        )\n",
        "        documents.append(doc)\n",
        "\n",
        "    # Add company research data\n",
        "    for company_name, data in SAMPLE_COMPANIES.items():\n",
        "        content = f\"\"\"\n",
        "Company: {company_name}\n",
        "Industry: {data['industry']}\n",
        "Size: {data['size']}\n",
        "Description: {data['description']}\n",
        "Tech Stack: {', '.join(data['tech_stack'])}\n",
        "Pain Points: {', '.join(data['pain_points'])}\n",
        "\"\"\"\n",
        "        doc = Document(\n",
        "            page_content=content,\n",
        "            metadata={\n",
        "                \"type\": \"company_research\",\n",
        "                \"company\": company_name,\n",
        "                \"industry\": data['industry']\n",
        "            }\n",
        "        )\n",
        "        documents.append(doc)\n",
        "\n",
        "    # Create vector store\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=documents,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=\"./sales_chroma_db\"\n",
        "    )\n",
        "\n",
        "    return vectorstore\n",
        "\n",
        "# Initialize vector store\n",
        "print(\"Creating vector database...\")\n",
        "vectorstore = create_pitch_vectorstore()\n",
        "print(f\"Vector store created with {len(SUCCESSFUL_PITCHES) + len(SAMPLE_COMPANIES)} documents\")\n",
        "\n",
        "# Test retrieval\n",
        "test_query = \"SaaS company scaling issues\"\n",
        "results = vectorstore.similarity_search(test_query, k=2)\n",
        "print(f\"\\nTest search for '{test_query}':\")\n",
        "print(f\"Found {len(results)} relevant documents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z9jcJwYJdcU",
        "outputId": "512530a1-7186-4ec6-cace-e66f07f9c3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating vector database...\n",
            "Vector store created with 6 documents\n",
            "\n",
            "Test search for 'SaaS company scaling issues':\n",
            "Found 2 relevant documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Agent Implementation - 5 Specialized Agents\n"
      ],
      "metadata": {
        "id": "V2aEdnO1M5jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LLM\n",
        "llm = ChatOpenAI(temperature=0.3, model=\"gpt-4\")\n",
        "\n",
        "# Shared context for passing information between agents\n",
        "class SharedContext:\n",
        "    def __init__(self):\n",
        "        self.company_name = \"\"\n",
        "        self.research_data = {}\n",
        "        self.analysis_results = {}\n",
        "        self.competitor_data = {}\n",
        "        self.personalization_data = {}\n",
        "        self.insights = {}\n",
        "        self.processing_time = {}\n",
        "\n",
        "    def update(self, key: str, value: Any):\n",
        "        setattr(self, key, value)\n",
        "\n",
        "    def get_full_context(self) -> Dict[str, Any]:\n",
        "        return {\n",
        "            \"company_name\": self.company_name,\n",
        "            \"research_data\": self.research_data,\n",
        "            \"analysis_results\": self.analysis_results,\n",
        "            \"competitor_data\": self.competitor_data,\n",
        "            \"personalization_data\": self.personalization_data,\n",
        "            \"insights\": self.insights\n",
        "        }\n",
        "\n",
        "shared_context = SharedContext()\n",
        "\n",
        "# 1. RESEARCH AGENT\n",
        "def research_company(company_name: str) -> str:\n",
        "    \"\"\"Research agent that gathers company information\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    shared_context.company_name = company_name\n",
        "\n",
        "    # Scrape company data\n",
        "    company_data = web_scraper.scrape_company_website(company_name)\n",
        "    news = web_scraper.scrape_company_news(company_name)\n",
        "    tech_stack = web_scraper.scrape_tech_stack(company_name)\n",
        "\n",
        "    research_results = {\n",
        "        \"basic_info\": company_data.get(\"data\", {}),\n",
        "        \"recent_news\": news,\n",
        "        \"tech_stack\": tech_stack,\n",
        "        \"research_timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    shared_context.research_data = research_results\n",
        "    shared_context.processing_time[\"research\"] = time.time() - start_time\n",
        "\n",
        "    return f\"\"\"\n",
        "Research completed for {company_name}:\n",
        "- Industry: {research_results['basic_info'].get('industry', 'Unknown')}\n",
        "- Size: {research_results['basic_info'].get('company_size', 'Unknown')}\n",
        "- Recent developments: {len(news)} news items found\n",
        "- Tech stack identified: {', '.join(tech_stack[:3])}...\n",
        "\"\"\"\n",
        "\n",
        "research_tool = Tool(\n",
        "    name=\"research_company\",\n",
        "    description=\"Research a company by gathering website data, news, and tech stack\",\n",
        "    func=research_company\n",
        ")\n",
        "\n",
        "# 2. ANALYSIS AGENT\n",
        "def analyze_company() -> str:\n",
        "    \"\"\"Analysis agent that identifies pain points and opportunities\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    company_data = web_scraper.get_company_insights(shared_context.company_name)\n",
        "\n",
        "    analysis = {\n",
        "        \"pain_points\": company_data.get(\"pain_points\", []),\n",
        "        \"growth_signals\": [],\n",
        "        \"opportunities\": []\n",
        "    }\n",
        "\n",
        "    # Analyze recent news for growth signals\n",
        "    for news in shared_context.research_data.get(\"recent_news\", []):\n",
        "        if \"funding\" in news.lower() or \"raised\" in news.lower():\n",
        "            analysis[\"growth_signals\"].append(\"Recent funding - likely scaling\")\n",
        "        if \"acquisition\" in news.lower():\n",
        "            analysis[\"growth_signals\"].append(\"M&A activity - integration needs\")\n",
        "        if \"hiring\" in news.lower():\n",
        "            analysis[\"growth_signals\"].append(\"Rapid hiring - growing pains\")\n",
        "\n",
        "    # Generate opportunities based on pain points\n",
        "    for pain_point in analysis[\"pain_points\"]:\n",
        "        if \"scaling\" in pain_point.lower():\n",
        "            analysis[\"opportunities\"].append(\"Infrastructure optimization\")\n",
        "        if \"manual\" in pain_point.lower():\n",
        "            analysis[\"opportunities\"].append(\"Process automation\")\n",
        "        if \"integration\" in pain_point.lower():\n",
        "            analysis[\"opportunities\"].append(\"API/Integration platform\")\n",
        "\n",
        "    shared_context.analysis_results = analysis\n",
        "    shared_context.processing_time[\"analysis\"] = time.time() - start_time\n",
        "\n",
        "    return f\"\"\"\n",
        "Analysis complete:\n",
        "- Identified {len(analysis['pain_points'])} pain points\n",
        "- Found {len(analysis['growth_signals'])} growth signals\n",
        "- Discovered {len(analysis['opportunities'])} opportunities\n",
        "Top pain point: {analysis['pain_points'][0] if analysis['pain_points'] else 'None identified'}\n",
        "\"\"\"\n",
        "\n",
        "analysis_tool = Tool(\n",
        "    name=\"analyze_company\",\n",
        "    description=\"Analyze company data to identify pain points and opportunities\",\n",
        "    func=analyze_company\n",
        ")\n",
        "\n",
        "# 3. COMPETITOR AGENT\n",
        "def analyze_competitors() -> str:\n",
        "    \"\"\"Competitor agent that analyzes competitive landscape\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    company_data = web_scraper.get_company_insights(shared_context.company_name)\n",
        "    competitors = company_data.get(\"competitors\", [])\n",
        "\n",
        "    competitor_analysis = {\n",
        "        \"main_competitors\": competitors,\n",
        "        \"market_position\": \"Challenger\" if len(competitors) > 2 else \"Leader\",\n",
        "        \"differentiation_opportunities\": [],\n",
        "        \"competitive_advantages\": []\n",
        "    }\n",
        "\n",
        "    # Simulate competitive analysis\n",
        "    if \"Scaling infrastructure\" in shared_context.analysis_results.get(\"pain_points\", []):\n",
        "        competitor_analysis[\"differentiation_opportunities\"].append(\n",
        "            \"Better scaling capabilities than \" + competitors[0] if competitors else \"competitors\"\n",
        "        )\n",
        "\n",
        "    shared_context.competitor_data = competitor_analysis\n",
        "    shared_context.processing_time[\"competitor\"] = time.time() - start_time\n",
        "\n",
        "    return f\"\"\"\n",
        "Competitive analysis:\n",
        "- Main competitors: {', '.join(competitors[:3])}\n",
        "- Market position: {competitor_analysis['market_position']}\n",
        "- Key differentiation opportunity identified\n",
        "\"\"\"\n",
        "\n",
        "competitor_tool = Tool(\n",
        "    name=\"analyze_competitors\",\n",
        "    description=\"Analyze competitive landscape and positioning\",\n",
        "    func=analyze_competitors\n",
        ")\n",
        "\n",
        "# 4. PERSONALIZATION AGENT\n",
        "def create_personalized_outreach() -> str:\n",
        "    \"\"\"Personalization agent that creates tailored messaging\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Search for similar successful pitches\n",
        "    pain_point = shared_context.analysis_results.get(\"pain_points\", [\"general\"])[0]\n",
        "    similar_pitches = vectorstore.similarity_search(\n",
        "        f\"{shared_context.research_data['basic_info'].get('industry')} {pain_point}\",\n",
        "        k=2\n",
        "    )\n",
        "\n",
        "    # Generate personalized outreach\n",
        "    personalization = {\n",
        "        \"email_subject\": f\"Re: {shared_context.company_name}'s recent {shared_context.research_data.get('recent_news', ['announcement'])[0]}\",\n",
        "        \"opening_line\": f\"Congrats on {shared_context.research_data.get('recent_news', ['your recent success'])[0]}!\",\n",
        "        \"pain_point_reference\": pain_point,\n",
        "        \"value_proposition\": \"We can help reduce this challenge by 40-60%\",\n",
        "        \"social_proof\": \"Similar to how we helped [similar company]\",\n",
        "        \"cta\": \"Worth a quick 15-min call next week?\",\n",
        "        \"personalization_score\": 0.85\n",
        "    }\n",
        "\n",
        "    # Build email template\n",
        "    email_template = f\"\"\"\n",
        "Subject: {personalization['email_subject']}\n",
        "\n",
        "Hi [Name],\n",
        "\n",
        "{personalization['opening_line']}\n",
        "\n",
        "I noticed that as {shared_context.company_name} scales, {personalization['pain_point_reference']} might be becoming a challenge.\n",
        "\n",
        "{personalization['value_proposition']}, {personalization['social_proof']}.\n",
        "\n",
        "{personalization['cta']}\n",
        "\n",
        "Best,\n",
        "[Your name]\n",
        "\"\"\"\n",
        "\n",
        "    personalization[\"email_template\"] = email_template\n",
        "    shared_context.personalization_data = personalization\n",
        "    shared_context.processing_time[\"personalization\"] = time.time() - start_time\n",
        "\n",
        "    return f\"\"\"\n",
        "Personalized outreach created:\n",
        "- Subject line personalization score: {personalization['personalization_score']}\n",
        "- Referenced recent news: Yes\n",
        "- Pain point addressed: {pain_point}\n",
        "- Similar successful pitch found: Yes\n",
        "\"\"\"\n",
        "\n",
        "personalization_tool = Tool(\n",
        "    name=\"create_personalized_outreach\",\n",
        "    description=\"Create personalized email outreach based on research\",\n",
        "    func=create_personalized_outreach\n",
        ")\n",
        "\n",
        "# 5. INSIGHTS AGENT\n",
        "def generate_strategic_insights() -> str:\n",
        "    \"\"\"Insights agent that provides strategic recommendations\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    insights = {\n",
        "        \"engagement_strategy\": \"\",\n",
        "        \"talking_points\": [],\n",
        "        \"objection_handling\": {},\n",
        "        \"follow_up_strategy\": \"\",\n",
        "        \"success_probability\": 0.0\n",
        "    }\n",
        "\n",
        "    # Generate engagement strategy\n",
        "    if \"Recent funding\" in str(shared_context.analysis_results.get(\"growth_signals\", [])):\n",
        "        insights[\"engagement_strategy\"] = \"High-priority: Post-funding scaling needs\"\n",
        "        insights[\"success_probability\"] = 0.75\n",
        "    else:\n",
        "        insights[\"engagement_strategy\"] = \"Standard: Operational efficiency focus\"\n",
        "        insights[\"success_probability\"] = 0.45\n",
        "\n",
        "    # Generate talking points\n",
        "    insights[\"talking_points\"] = [\n",
        "        f\"Their {shared_context.research_data['basic_info'].get('industry')} expertise\",\n",
        "        f\"Recent {shared_context.research_data.get('recent_news', ['development'])[0]}\",\n",
        "        f\"How we solve {shared_context.analysis_results.get('pain_points', ['challenges'])[0]}\"\n",
        "    ]\n",
        "\n",
        "    # Objection handling\n",
        "    insights[\"objection_handling\"] = {\n",
        "        \"Too expensive\": \"ROI typically 3-6 months, can start with pilot\",\n",
        "        \"Already have solution\": \"Our differentiator is [specific feature]\",\n",
        "        \"Not a priority\": f\"Given your {shared_context.analysis_results.get('growth_signals', ['growth'])[0]}, this becomes critical soon\"\n",
        "    }\n",
        "\n",
        "    shared_context.insights = insights\n",
        "    shared_context.processing_time[\"insights\"] = time.time() - start_time\n",
        "\n",
        "    return f\"\"\"\n",
        "Strategic insights generated:\n",
        "- Engagement strategy: {insights['engagement_strategy']}\n",
        "- Success probability: {insights['success_probability']*100:.0f}%\n",
        "- Key talking points: {len(insights['talking_points'])}\n",
        "- Objection handlers prepared: {len(insights['objection_handling'])}\n",
        "\"\"\"\n",
        "\n",
        "insights_tool = Tool(\n",
        "    name=\"generate_strategic_insights\",\n",
        "    description=\"Generate strategic recommendations for engagement\",\n",
        "    func=generate_strategic_insights\n",
        ")\n",
        "\n",
        "print(\"All 5 specialized agents created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8m5lkP0Jg30",
        "outputId": "6a730733-337e-4015-cab6-84291dc8a96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All 5 specialized agents created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Orchestrator Agent - Coordinating the Workflow\n"
      ],
      "metadata": {
        "id": "iFMJbK_3M_A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the orchestrator agent that manages all other agents\n",
        "orchestrator_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are the Lead Generation Orchestrator that coordinates a team of specialized agents to research and prepare personalized outreach for B2B sales.\n",
        "\n",
        "Your team consists of:\n",
        "1. Research Agent - Gathers company information, news, and tech stack\n",
        "2. Analysis Agent - Identifies pain points and opportunities\n",
        "3. Competitor Agent - Analyzes competitive landscape\n",
        "4. Personalization Agent - Creates tailored outreach messages\n",
        "5. Insights Agent - Provides strategic recommendations\n",
        "\n",
        "For each company, you MUST use ALL agents in sequence to build comprehensive intelligence. Each agent builds upon the previous agent's work.\n",
        "\n",
        "Always follow this workflow:\n",
        "1. First, use research_company to gather basic information\n",
        "2. Then, use analyze_company to identify pain points\n",
        "3. Next, use analyze_competitors for competitive intelligence\n",
        "4. Then, use create_personalized_outreach for messaging\n",
        "5. Finally, use generate_strategic_insights for strategy\n",
        "\n",
        "Provide clear status updates as you progress through each agent.\"\"\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])\n",
        "\n",
        "# Create all tools list\n",
        "all_tools = [\n",
        "    research_tool,\n",
        "    analysis_tool,\n",
        "    competitor_tool,\n",
        "    personalization_tool,\n",
        "    insights_tool\n",
        "]\n",
        "\n",
        "# Create the orchestrator agent\n",
        "orchestrator_agent = create_openai_functions_agent(\n",
        "    llm=llm,\n",
        "    tools=all_tools,\n",
        "    prompt=orchestrator_prompt\n",
        ")\n",
        "\n",
        "# Create agent executor with memory\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=orchestrator_agent,\n",
        "    tools=all_tools,\n",
        "    memory=memory,\n",
        "    verbose=True,  # Shows the agent's reasoning\n",
        "    max_iterations=10,\n",
        "    return_intermediate_steps=True\n",
        ")\n",
        "\n",
        "print(\"Orchestrator agent created and ready to coordinate all agents!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nncgoo43NB5T",
        "outputId": "186531dc-5770-4008-d371-561f00067a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orchestrator agent created and ready to coordinate all agents!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Observability & Metrics Dashboard\n"
      ],
      "metadata": {
        "id": "W9Gv3S-GNFAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics tracking system\n",
        "class MetricsTracker:\n",
        "    def __init__(self):\n",
        "        self.metrics = {\n",
        "            \"total_companies_processed\": 0,\n",
        "            \"avg_processing_time\": 0,\n",
        "            \"agent_performance\": {},\n",
        "            \"success_scores\": [],\n",
        "            \"api_costs\": []\n",
        "        }\n",
        "\n",
        "    def track_processing(self, company_name: str, context: SharedContext):\n",
        "        \"\"\"Track metrics for a processed company\"\"\"\n",
        "        self.metrics[\"total_companies_processed\"] += 1\n",
        "\n",
        "        # Track agent performance\n",
        "        for agent, time_taken in context.processing_time.items():\n",
        "            if agent not in self.metrics[\"agent_performance\"]:\n",
        "                self.metrics[\"agent_performance\"][agent] = []\n",
        "            self.metrics[\"agent_performance\"][agent].append(time_taken)\n",
        "\n",
        "        # Track success probability\n",
        "        success_prob = context.insights.get(\"success_probability\", 0)\n",
        "        self.metrics[\"success_scores\"].append(success_prob)\n",
        "\n",
        "        # Estimate API costs (rough estimate)\n",
        "        estimated_tokens = len(str(context.get_full_context())) / 4\n",
        "        estimated_cost = (estimated_tokens / 1000) * 0.002  # Rough estimate\n",
        "        self.metrics[\"api_costs\"].append(estimated_cost)\n",
        "\n",
        "    def get_dashboard_data(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get data for dashboard visualization\"\"\"\n",
        "        return {\n",
        "            \"total_processed\": self.metrics[\"total_companies_processed\"],\n",
        "            \"avg_success_probability\": sum(self.metrics[\"success_scores\"]) / len(self.metrics[\"success_scores\"]) if self.metrics[\"success_scores\"] else 0,\n",
        "            \"total_cost\": sum(self.metrics[\"api_costs\"]),\n",
        "            \"agent_avg_times\": {\n",
        "                agent: sum(times) / len(times) if times else 0\n",
        "                for agent, times in self.metrics[\"agent_performance\"].items()\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Initialize metrics tracker\n",
        "metrics_tracker = MetricsTracker()\n",
        "\n",
        "# Create visualization dashboard\n",
        "def create_performance_dashboard(metrics_data: Dict[str, Any]):\n",
        "    \"\"\"Create a performance dashboard using Plotly\"\"\"\n",
        "\n",
        "    # Agent performance bar chart\n",
        "    if metrics_data[\"agent_avg_times\"]:\n",
        "        agents = list(metrics_data[\"agent_avg_times\"].keys())\n",
        "        times = list(metrics_data[\"agent_avg_times\"].values())\n",
        "\n",
        "        fig1 = go.Figure(data=[\n",
        "            go.Bar(x=agents, y=times, marker_color='lightblue')\n",
        "        ])\n",
        "        fig1.update_layout(\n",
        "            title=\"Average Agent Processing Time (seconds)\",\n",
        "            xaxis_title=\"Agent\",\n",
        "            yaxis_title=\"Time (s)\"\n",
        "        )\n",
        "        fig1.show()\n",
        "\n",
        "    # Success probability gauge\n",
        "    fig2 = go.Figure(go.Indicator(\n",
        "        mode=\"gauge+number+delta\",\n",
        "        value=metrics_data[\"avg_success_probability\"] * 100,\n",
        "        domain={'x': [0, 1], 'y': [0, 1]},\n",
        "        title={'text': \"Average Success Probability (%)\"},\n",
        "        gauge={\n",
        "            'axis': {'range': [None, 100]},\n",
        "            'bar': {'color': \"darkgreen\"},\n",
        "            'steps': [\n",
        "                {'range': [0, 50], 'color': \"lightgray\"},\n",
        "                {'range': [50, 80], 'color': \"gray\"}\n",
        "            ],\n",
        "            'threshold': {\n",
        "                'line': {'color': \"red\", 'width': 4},\n",
        "                'thickness': 0.75,\n",
        "                'value': 90\n",
        "            }\n",
        "        }\n",
        "    ))\n",
        "    fig2.show()\n",
        "\n",
        "    print(f\"\\nDashboard Summary:\")\n",
        "    print(f\"- Total Companies Processed: {metrics_data['total_processed']}\")\n",
        "    print(f\"- Average Success Probability: {metrics_data['avg_success_probability']*100:.1f}%\")\n",
        "    print(f\"- Estimated Total API Cost: ${metrics_data['total_cost']:.2f}\")\n",
        "\n",
        "print(\"Observability system initialized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pq38tAzM7II",
        "outputId": "20a622f0-387b-490d-da59-dd73eda31cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observability system initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Complete Sales Intelligence Demo\n"
      ],
      "metadata": {
        "id": "ihka_MUgNDd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_lead(company_name: str) -> Dict[str, Any]:\n",
        "    \"\"\"Process a single lead through the entire pipeline\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ðŸš€ Processing Lead: {company_name}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Run the orchestrator agent\n",
        "        result = agent_executor.invoke({\n",
        "            \"input\": f\"Research {company_name} and prepare a complete sales intelligence report with personalized outreach\"\n",
        "        })\n",
        "\n",
        "        # Track metrics\n",
        "        metrics_tracker.track_processing(company_name, shared_context)\n",
        "\n",
        "        # Prepare final report\n",
        "        final_report = {\n",
        "            \"company_name\": company_name,\n",
        "            \"processing_time\": time.time() - start_time,\n",
        "            \"research_summary\": shared_context.research_data,\n",
        "            \"pain_points\": shared_context.analysis_results.get(\"pain_points\", []),\n",
        "            \"opportunities\": shared_context.analysis_results.get(\"opportunities\", []),\n",
        "            \"competitors\": shared_context.competitor_data.get(\"main_competitors\", []),\n",
        "            \"personalized_email\": shared_context.personalization_data.get(\"email_template\", \"\"),\n",
        "            \"success_probability\": shared_context.insights.get(\"success_probability\", 0),\n",
        "            \"strategic_insights\": shared_context.insights,\n",
        "            \"agent_output\": result[\"output\"]\n",
        "        }\n",
        "\n",
        "        return final_report\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {company_name}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Demo: Process multiple companies\n",
        "def run_full_demo():\n",
        "    \"\"\"Run a complete demonstration of the system\"\"\"\n",
        "\n",
        "    print(\"ðŸŽ¯ AI SALES INTELLIGENCE PLATFORM DEMO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    companies_to_process = list(SAMPLE_COMPANIES.keys())\n",
        "    all_reports = []\n",
        "\n",
        "    for company in companies_to_process:\n",
        "        # Reset shared context for each company\n",
        "        global shared_context\n",
        "        shared_context = SharedContext()\n",
        "\n",
        "        report = process_lead(company)\n",
        "        if report:\n",
        "            all_reports.append(report)\n",
        "\n",
        "            # Display results\n",
        "            print(f\"\\nðŸ“Š FINAL REPORT FOR {company}\")\n",
        "            print(\"-\" * 40)\n",
        "            print(f\"âœ… Processing Time: {report['processing_time']:.2f} seconds\")\n",
        "            print(f\"âœ… Success Probability: {report['success_probability']*100:.0f}%\")\n",
        "            print(f\"âœ… Pain Points Identified: {len(report['pain_points'])}\")\n",
        "            print(f\"âœ… Main Competitors: {', '.join(report['competitors'][:3])}\")\n",
        "\n",
        "            print(f\"\\nðŸ“§ PERSONALIZED EMAIL:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(report['personalized_email'][:500] + \"...\")\n",
        "\n",
        "            print(f\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
        "            print(f\"- Strategy: {report['strategic_insights'].get('engagement_strategy')}\")\n",
        "            print(f\"- Top Talking Point: {report['strategic_insights'].get('talking_points', ['N/A'])[0]}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        time.sleep(1)  # Brief pause between companies\n",
        "\n",
        "    # Show performance dashboard\n",
        "    print(\"\\nðŸ“ˆ PERFORMANCE METRICS DASHBOARD\")\n",
        "    print(\"=\" * 60)\n",
        "    dashboard_data = metrics_tracker.get_dashboard_data()\n",
        "    create_performance_dashboard(dashboard_data)\n",
        "\n",
        "    return all_reports\n",
        "\n",
        "# Run the demo\n",
        "print(\"Starting Sales Intelligence Demo...\\n\")\n",
        "demo_results = run_full_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uApUaO59NIer",
        "outputId": "256f8a35-81a2-4926-ad4f-4a0bf0e08944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Sales Intelligence Demo...\n",
            "\n",
            "ðŸŽ¯ AI SALES INTELLIGENCE PLATFORM DEMO\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "ðŸš€ Processing Lead: TechCorp Solutions\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `research_company` with `TechCorp Solutions`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
            "Research completed for TechCorp Solutions:\n",
            "- Industry: SaaS\n",
            "- Size: 50-200\n",
            "- Recent developments: 3 news items found\n",
            "- Tech stack identified: React, Node.js, AWS...\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `analyze_company` with `TechCorp Solutions`\n",
            "responded: The Research Agent has completed the initial research on TechCorp Solutions. They are a SaaS company with a size of 50-200 employees. Their tech stack includes React, Node.js, and AWS. There are also some recent developments that we need to look into.\n",
            "\n",
            "Now, let's move on to the Analysis Agent to identify potential pain points and opportunities.\n",
            "\n",
            "\u001b[0mError processing TechCorp Solutions: analyze_company() takes 0 positional arguments but 1 was given\n",
            "\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "ðŸš€ Processing Lead: DataFlow Analytics\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `research_company` with `DataFlow Analytics`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
            "Research completed for DataFlow Analytics:\n",
            "- Industry: Data Analytics\n",
            "- Size: 200-500\n",
            "- Recent developments: 3 news items found\n",
            "- Tech stack identified: Python, Spark, Kubernetes...\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `analyze_company` with `DataFlow Analytics`\n",
            "responded: Research Agent has completed the initial research on DataFlow Analytics. The company operates in the Data Analytics industry and has a workforce of between 200 and 500 employees. They use a tech stack that includes Python, Spark, and Kubernetes. Now, let's move to the Analysis Agent to identify potential pain points and opportunities.\n",
            "\n",
            "\u001b[0mError processing DataFlow Analytics: analyze_company() takes 0 positional arguments but 1 was given\n",
            "\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "ðŸš€ Processing Lead: GreenTech Industries\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `research_company` with `GreenTech Industries`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\n",
            "Research completed for GreenTech Industries:\n",
            "- Industry: CleanTech\n",
            "- Size: 100-300\n",
            "- Recent developments: 3 news items found\n",
            "- Tech stack identified: Python, TensorFlow, Azure...\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `analyze_company` with `GreenTech Industries`\n",
            "responded: Great, we have completed the initial research on GreenTech Industries. They are a CleanTech company with a size of 100-300 employees. They have been mentioned in 3 recent news items and their tech stack includes Python, TensorFlow, and Azure.\n",
            "\n",
            "Now, let's move to the next step, which is to analyze the company to identify potential pain points and opportunities.\n",
            "\n",
            "\u001b[0mError processing GreenTech Industries: analyze_company() takes 0 positional arguments but 1 was given\n",
            "\n",
            "============================================================\n",
            "\n",
            "ðŸ“ˆ PERFORMANCE METRICS DASHBOARD\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"85789f28-1f20-4291-a154-c80ad43909c1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"85789f28-1f20-4291-a154-c80ad43909c1\")) {                    Plotly.newPlot(                        \"85789f28-1f20-4291-a154-c80ad43909c1\",                        [{\"domain\":{\"x\":[0,1],\"y\":[0,1]},\"gauge\":{\"axis\":{\"range\":[null,100]},\"bar\":{\"color\":\"darkgreen\"},\"steps\":[{\"color\":\"lightgray\",\"range\":[0,50]},{\"color\":\"gray\",\"range\":[50,80]}],\"threshold\":{\"line\":{\"color\":\"red\",\"width\":4},\"thickness\":0.75,\"value\":90}},\"mode\":\"gauge+number+delta\",\"title\":{\"text\":\"Average Success Probability (%)\"},\"value\":0,\"type\":\"indicator\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('85789f28-1f20-4291-a154-c80ad43909c1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dashboard Summary:\n",
            "- Total Companies Processed: 0\n",
            "- Average Success Probability: 0.0%\n",
            "- Estimated Total API Cost: $0.00\n"
          ]
        }
      ]
    }
  ]
}