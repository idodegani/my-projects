{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ RAG-Powered API Documentation Assistant  \n",
        "### A Complete Implementation for Intelligent Documentation Search, Retrieval, and Code Generation\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Project Overview & Architecture\n",
        "\n",
        "### ü§ñ What This Project Does\n",
        "\n",
        "This notebook implements an intelligent documentation assistant that can answer questions like:\n",
        "\n",
        "> **\"How do I do Y with Tool X?\"**\n",
        "\n",
        "By automatically:\n",
        "\n",
        "- üîç **Finding** official documentation through intelligent web search  \n",
        "- üß† **Ingesting** documentation into a vector store using state-of-the-art embeddings  \n",
        "- üìö **Retrieving** the most relevant passages based on semantic similarity to your question  \n",
        "- üßë‚Äçüíª **Generating** executable code that directly answers your question  \n",
        "- üìé **Providing** clear explanations with proper citations back to the documentation  \n",
        "\n",
        "---\n",
        "\n",
        "## üèóÔ∏è Architecture Deep Dive\n",
        "\n",
        "The system follows a sophisticated pipeline architecture:\n"
      ],
      "metadata": {
        "id": "Ymz6oIwyeyK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "XztmtDqGfirg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Key Technologies Used\n",
        "\n",
        "- **LangChain** ‚Äì Orchestrates LLM operations and document processing  \n",
        "- **ChromaDB** ‚Äì Vector database for fast and accurate semantic search  \n",
        "- **OpenAI Embeddings** ‚Äì Converts text into high-dimensional vector representations  \n",
        "- **GPT-3.5 / GPT-4** ‚Äì Generates code and natural language explanations  \n",
        "- **BeautifulSoup** ‚Äì Extracts structured content from raw HTML pages  \n",
        "- **DuckDuckGo Search** ‚Äì Enables web search without hitting API rate limits  \n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è 1. Environment Setup & Dependencies\n",
        "\n",
        "### üì¶ Installing Required Packages\n",
        "\n",
        "This step installs all necessary Python packages for:\n",
        "\n",
        "- üîÑ **LLM orchestration**: `langchain`  \n",
        "- üß† **Vector storage**: `chromadb`  \n",
        "- üåê **Web scraping**: `beautifulsoup4`  \n",
        "- üîç **Search functionality**: `duckduckgo-search`  \n",
        "- üìä **Data display**: `pandas`, `tabulate`  \n"
      ],
      "metadata": {
        "id": "lMF7bXOWfpdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core dependencies for the RAG pipeline\n",
        "!pip install -q langchain langchain-community langchain-openai  # LangChain ecosystem for LLM orchestration\n",
        "!pip install -q chromadb  # Vector database for storing and searching documentation embeddings\n",
        "!pip install -q beautifulsoup4 requests  # Web scraping to extract documentation content\n",
        "!pip install -q pandas tabulate  # Data manipulation and pretty table display\n",
        "!pip install -q tiktoken  # Token counting for OpenAI models\n",
        "\n",
        "# Search functionality - DuckDuckGo provides free web search without API keys\n",
        "!pip install -q duckduckgo-search\n",
        "\n",
        "# Enhanced display capabilities for Jupyter\n",
        "!pip install -q IPython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQQLxwRBfrDs",
        "outputId": "82e000b8-0354-4102-b111-e66d197b1bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/70.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q serpapi\n",
        "from serpapi import GoogleSearch  # SerpAPI for real web search\n"
      ],
      "metadata": {
        "id": "JkriUNmDatlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ddgs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVIQiDATj1xg",
        "outputId": "40028f9d-71cc-4adc-ed4d-e48e9e6075e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ddgs\n",
            "  Downloading ddgs-9.5.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from ddgs) (8.2.1)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from ddgs) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from ddgs) (5.4.0)\n",
            "Downloading ddgs-9.5.1-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: ddgs\n",
            "Successfully installed ddgs-9.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing All Required Libraries\n",
        "This cell imports all the libraries we'll use throughout the notebook. Each import is grouped by functionality for better organization."
      ],
      "metadata": {
        "id": "nFU8E3ecfz8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "from typing import List, Dict, Tuple, Optional, Any\n",
        "from datetime import datetime\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "# Data manipulation and display\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Web scraping utilities\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse, urljoin\n",
        "\n",
        "# LangChain components for RAG pipeline\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Smart text chunking\n",
        "from langchain.embeddings import OpenAIEmbeddings  # Convert text to vectors\n",
        "from langchain.vectorstores import Chroma  # Vector database\n",
        "from langchain.schema import Document  # Document abstraction\n",
        "from langchain.chat_models import ChatOpenAI  # GPT interface\n",
        "from langchain.prompts import ChatPromptTemplate  # Prompt engineering\n",
        "from langchain.chains import LLMChain  # Chain LLM calls\n",
        "\n",
        "# Search functionality\n",
        "from duckduckgo_search import DDGS  # Free web search API\n",
        "\n",
        "# Jupyter display utilities\n",
        "from IPython.display import display, HTML, Markdown, Code\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV7wwTete0Zz",
        "outputId": "44047bf5-ab97-4bae-8ea1-38213010ad4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### API Key Configuration\n",
        "This section handles OpenAI API key setup."
      ],
      "metadata": {
        "id": "_e_ym-Sif4gB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "IMPORTANT: You need an OpenAI API key to use this notebook.\n",
        "\n",
        "To get your API key:\n",
        "1. Go to https://platform.openai.com/api-keys\n",
        "2. Sign up or log in to your OpenAI account\n",
        "3. Click \"Create new secret key\"\n",
        "4. Copy the key (it starts with 'sk-')\n",
        "\n",
        "There are three ways to set your API key:\n",
        "\"\"\"\n",
        "\n",
        "# Method 1: Direct assignment (NOT RECOMMENDED for production or sharing)\n",
        "# Uncomment the line below and replace with your actual key\n",
        "# os.environ['OPENAI_API_KEY'] = 'sk-your-api-key-here'\n",
        "\n",
        "# Method 2: Using Google Colab secrets (RECOMMENDED for Colab users)\n",
        "# This keeps your API key secure and separate from your code\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] ='sk-'\n",
        "    print(\"‚úÖ OpenAI API key loaded successfully from Colab secrets!\")\n",
        "    print(\"   Your API key is secure and ready to use.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è  Could not load API key from Colab secrets.\")\n",
        "    print(\"\\nTo add your API key to Colab secrets:\")\n",
        "    print(\"1. Click the üîë key icon in the left sidebar\")\n",
        "    print(\"2. Click 'Add new secret'\")\n",
        "    print(\"3. Name it: OPENAI_API_KEY\")\n",
        "    print(\"4. Value: paste your OpenAI API key\")\n",
        "    print(\"5. Click 'Save' and re-run this cell\")\n",
        "    print(\"\\nAlternatively, uncomment Method 1 above (less secure)\")\n",
        "\n",
        "# Method 3: Environment variable (for local development)\n",
        "# Set the OPENAI_API_KEY environment variable in your shell before running Jupyter\n",
        "\n",
        "# Verify API key is set\n",
        "if os.environ.get('OPENAI_API_KEY'):\n",
        "    # Show partial key for verification (keeping most hidden for security)\n",
        "    key = os.environ['OPENAI_API_KEY']\n",
        "    print(f\"\\nüîê API Key configured: {key[:8]}...{key[-4:]}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No API key found. Please set it using one of the methods above.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgmnVWWef3ND",
        "outputId": "c411296d-a0a1-4852-b684-40ef305aee53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OpenAI API key loaded successfully from Colab secrets!\n",
            "   Your API key is secure and ready to use.\n",
            "\n",
            "üîê API Key configured: sk-proj-...OyUA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üß© 2. Core Components & Utilities\n",
        "\n",
        "### üåê Documentation Web Crawler\n",
        "\n",
        "The `DocumentationCrawler` class is responsible for:\n",
        "\n",
        "- üîé **Finding** relevant documentation pages via intelligent web search  \n",
        "- üåç **Fetching** and returning the content of those pages  \n",
        "- üß≠ Uses smart heuristics to prioritize **official documentation** sources\n"
      ],
      "metadata": {
        "id": "7gam34jagNcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentationCrawler:\n",
        "    \"\"\"\n",
        "    Handles web search and documentation retrieval.\n",
        "\n",
        "    This class is responsible for:\n",
        "    1. Searching the web for official API documentation\n",
        "    2. Filtering results to find the most relevant documentation URLs\n",
        "    3. Fetching and cleaning the documentation content\n",
        "    4. Handling errors gracefully when documentation can't be found\n",
        "\n",
        "    The crawler uses DuckDuckGo search (free, no API key required) and includes\n",
        "    smart heuristics to identify documentation pages vs other content.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the crawler with DuckDuckGo search engine.\"\"\"\n",
        "        self.ddgs = DDGS()  # DuckDuckGo search instance\n",
        "        # Common documentation URL patterns to prioritize\n",
        "        self.doc_keywords = ['docs', 'documentation', 'api', 'reference', 'guide', 'manual']\n",
        "        # Headers to avoid being blocked by websites\n",
        "        self.headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "    def search_documentation(self, tool_name: str, max_results: int = 5) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Search for official documentation of a tool/library.\n",
        "\n",
        "        Args:\n",
        "            tool_name (str): Name of the tool/library to search for (e.g., \"pandas\", \"requests\")\n",
        "            max_results (int): Maximum number of search results to consider\n",
        "\n",
        "        Returns:\n",
        "            List[Dict]: List of documentation results, each containing:\n",
        "                - url: The documentation URL\n",
        "                - title: Page title\n",
        "                - snippet: Brief description/preview\n",
        "\n",
        "        The method uses intelligent filtering to prioritize official documentation\n",
        "        over blog posts, tutorials, or other content.\n",
        "        \"\"\"\n",
        "        # Craft a search query that's likely to find official docs\n",
        "        # We add multiple keywords to improve search accuracy\n",
        "        query = f\"{tool_name} official documentation API reference site:*.org OR site:*.io OR site:*.com\"\n",
        "\n",
        "        print(f\"üîç Searching for: {query}\")\n",
        "\n",
        "        try:\n",
        "            # Perform the search using DuckDuckGo\n",
        "            # We get raw results first, then filter them\n",
        "            raw_results = list(self.ddgs.text(query, max_results=max_results * 2))  # Get extra results for filtering\n",
        "\n",
        "            # Filter and score results to find actual documentation\n",
        "            doc_results = []\n",
        "\n",
        "            for result in raw_results:\n",
        "                url = result.get('href', '').lower()\n",
        "                title = result.get('title', '').lower()\n",
        "                snippet = result.get('body', '').lower()\n",
        "\n",
        "                # Calculate a relevance score based on documentation indicators\n",
        "                score = 0\n",
        "\n",
        "                # Check URL for documentation keywords\n",
        "                for keyword in self.doc_keywords:\n",
        "                    if keyword in url:\n",
        "                        score += 3  # URL match is strong signal\n",
        "                    if keyword in title:\n",
        "                        score += 2  # Title match is good signal\n",
        "                    if keyword in snippet:\n",
        "                        score += 1  # Content match is weak signal\n",
        "\n",
        "                # Boost score for likely official domains\n",
        "                if tool_name.lower() in url:\n",
        "                    score += 5  # Official domain likely contains tool name\n",
        "\n",
        "                # Only include results with decent documentation score\n",
        "                if score >= 3:\n",
        "                    doc_results.append({\n",
        "                        'url': result.get('href', ''),\n",
        "                        'title': result.get('title', ''),\n",
        "                        'snippet': result.get('body', ''),\n",
        "                        'score': score  # Internal use for sorting\n",
        "                    })\n",
        "\n",
        "            # Sort by relevance score and return top results\n",
        "            doc_results.sort(key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "            # Remove score before returning (internal use only)\n",
        "            for result in doc_results:\n",
        "                result.pop('score', None)\n",
        "\n",
        "            return doc_results[:max_results]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Search error: {e}\")\n",
        "            return []\n",
        "\n",
        "    def fetch_page_content(self, url: str, max_tokens: int = 10000) -> Tuple[str, bool]:\n",
        "        \"\"\"\n",
        "        Fetch and clean documentation content from a URL.\n",
        "\n",
        "        Args:\n",
        "            url (str): The URL to fetch documentation from\n",
        "            max_tokens (int): Maximum tokens to extract (1 token ‚âà 4 characters)\n",
        "                             This prevents memory issues with huge pages\n",
        "\n",
        "        Returns:\n",
        "            Tuple[str, bool]: (cleaned_content, success_flag)\n",
        "                - cleaned_content: Extracted and cleaned text from the page\n",
        "                - success_flag: True if fetch was successful, False otherwise\n",
        "\n",
        "        The method:\n",
        "        1. Fetches the HTML content\n",
        "        2. Removes navigation, scripts, styles, and other non-content elements\n",
        "        3. Extracts and cleans the text\n",
        "        4. Truncates to max_tokens if necessary\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"üì• Fetching content from: {url}\")\n",
        "\n",
        "            # Make the HTTP request with timeout to prevent hanging\n",
        "            response = requests.get(\n",
        "                url,\n",
        "                headers=self.headers,\n",
        "                timeout=10,  # 10 second timeout\n",
        "                allow_redirects=True  # Follow redirects to final documentation\n",
        "            )\n",
        "\n",
        "            # Check if request was successful\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Parse HTML with BeautifulSoup\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Remove elements that typically don't contain documentation content\n",
        "            # This significantly improves the quality of extracted text\n",
        "            noise_tags = [\n",
        "                'script',    # JavaScript code\n",
        "                'style',     # CSS styles\n",
        "                'nav',       # Navigation menus\n",
        "                'footer',    # Footer content\n",
        "                'header',    # Header content\n",
        "                'aside',     # Sidebar content\n",
        "                'meta',      # Metadata\n",
        "                'link',      # Link elements\n",
        "                'noscript'   # Noscript fallbacks\n",
        "            ]\n",
        "\n",
        "            for tag in noise_tags:\n",
        "                for element in soup.find_all(tag):\n",
        "                    element.decompose()  # Completely remove from tree\n",
        "\n",
        "            # Also remove common class/id patterns for ads, comments, etc.\n",
        "            for element in soup.find_all(class_=re.compile('(ad|advertisement|comment|social|share)')):\n",
        "                element.decompose()\n",
        "\n",
        "            # Extract text content\n",
        "            text = soup.get_text(separator='\\n', strip=True)\n",
        "\n",
        "            # Clean up the text\n",
        "            # Remove multiple newlines and excessive whitespace\n",
        "            lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
        "            content = '\\n'.join(lines)\n",
        "\n",
        "            # Estimate token count (rough approximation: 1 token ‚âà 4 characters)\n",
        "            estimated_tokens = len(content) / 4\n",
        "\n",
        "            # Truncate if content exceeds max_tokens\n",
        "            if estimated_tokens > max_tokens:\n",
        "                # Calculate character limit based on max tokens\n",
        "                char_limit = max_tokens * 4\n",
        "                content = content[:char_limit]\n",
        "                print(f\"‚ö†Ô∏è  Content truncated to ~{max_tokens} tokens\")\n",
        "\n",
        "            print(f\"‚úÖ Successfully fetched {len(content)} characters (~{int(len(content)/4)} tokens)\")\n",
        "            return content, True\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            # Handle specific request errors\n",
        "            print(f\"‚ùå Network error fetching {url}: {e}\")\n",
        "            return \"\", False\n",
        "        except Exception as e:\n",
        "            # Handle any other errors\n",
        "            print(f\"‚ùå Error processing {url}: {e}\")\n",
        "            return \"\", False"
      ],
      "metadata": {
        "id": "eu2IMWzOgHR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† RAG Document Processor\n",
        "\n",
        "The `RAGDocumentProcessor` handles the core Retrieval-Augmented Generation (RAG) functionality:\n",
        "\n",
        "- ‚úÇÔ∏è **Splits** long documents into manageable chunks  \n",
        "- üî¢ **Creates embeddings** for each chunk using OpenAI  \n",
        "- üì• **Stores** embeddings in a vector database (ChromaDB)  \n",
        "- üéØ **Retrieves** the most relevant passages based on user queries\n"
      ],
      "metadata": {
        "id": "VLyfG64ggT08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGDocumentProcessor:\n",
        "    \"\"\"\n",
        "    Handles document chunking, embedding, and vector storage for RAG.\n",
        "\n",
        "    This class is the heart of the RAG (Retrieval-Augmented Generation) system:\n",
        "    1. Splits large documents into manageable chunks\n",
        "    2. Creates vector embeddings for each chunk\n",
        "    3. Stores embeddings in a vector database\n",
        "    4. Retrieves relevant chunks based on semantic similarity\n",
        "\n",
        "    The processor uses OpenAI embeddings and ChromaDB for efficient\n",
        "    vector storage and retrieval.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):\n",
        "        \"\"\"\n",
        "        Initialize the RAG processor with configurable parameters.\n",
        "\n",
        "        Args:\n",
        "            chunk_size (int): Target size for each text chunk in characters\n",
        "            chunk_overlap (int): Number of characters to overlap between chunks\n",
        "                                This helps maintain context across chunk boundaries\n",
        "        \"\"\"\n",
        "        # Initialize OpenAI embeddings (uses API key from environment)\n",
        "        self.embeddings = OpenAIEmbeddings(\n",
        "            model=\"text-embedding-ada-002\"  # OpenAI's best embedding model\n",
        "        )\n",
        "\n",
        "        # Configure text splitter with smart splitting strategy\n",
        "        # RecursiveCharacterTextSplitter tries to split on natural boundaries\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap,\n",
        "            length_function=len,  # Use character count for chunk size\n",
        "            # Separators in order of preference (try paragraph breaks first)\n",
        "            separators=[\n",
        "                \"\\n\\n\",    # Paragraph breaks (most natural boundary)\n",
        "                \"\\n\",      # Line breaks\n",
        "                \". \",      # Sentence endings\n",
        "                \"! \",      # Exclamation sentences\n",
        "                \"? \",      # Question sentences\n",
        "                \";\",       # Semicolons\n",
        "                \",\",       # Commas\n",
        "                \" \",       # Words\n",
        "                \"\"         # Characters (last resort)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Vector store will be initialized when processing documents\n",
        "        self.vector_store = None\n",
        "\n",
        "        # Keep track of processed documents for reference\n",
        "        self.processed_docs = []\n",
        "\n",
        "    def process_documentation(self, content: str, source_url: str) -> Chroma:\n",
        "        \"\"\"\n",
        "        Process documentation content into a searchable vector store.\n",
        "\n",
        "        Args:\n",
        "            content (str): The documentation text to process\n",
        "            source_url (str): Source URL for metadata/attribution\n",
        "\n",
        "        Returns:\n",
        "            Chroma: The initialized vector store containing embedded chunks\n",
        "\n",
        "        This method:\n",
        "        1. Creates a Document object with metadata\n",
        "        2. Splits the document into optimal chunks\n",
        "        3. Adds metadata to each chunk for traceability\n",
        "        4. Creates embeddings and stores in ChromaDB\n",
        "        \"\"\"\n",
        "        print(\"üìÑ Processing documentation into vector store...\")\n",
        "\n",
        "        # Create a LangChain Document with the content and metadata\n",
        "        # Metadata is crucial for citations and source tracking\n",
        "        doc = Document(\n",
        "            page_content=content,\n",
        "            metadata={\n",
        "                \"source\": source_url,\n",
        "                \"processed_at\": datetime.now().isoformat(),\n",
        "                \"total_length\": len(content)\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Split the document into chunks\n",
        "        # This is where the magic happens - good chunking is critical for RAG\n",
        "        print(f\"üîÑ Splitting document into chunks (size: ~{self.text_splitter._chunk_size} chars)...\")\n",
        "        chunks = self.text_splitter.split_documents([doc])\n",
        "\n",
        "        print(f\"‚úÖ Created {len(chunks)} chunks\")\n",
        "\n",
        "        # Add detailed metadata to each chunk\n",
        "        # This helps with retrieval and citation generation\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            # Preserve original metadata\n",
        "            chunk.metadata.update({\n",
        "                'chunk_id': i,\n",
        "                'chunk_index': f\"{i + 1}/{len(chunks)}\",  # Human-readable index\n",
        "                'start_char': i * (self.text_splitter._chunk_size - self.text_splitter._chunk_overlap),\n",
        "                'chunk_size': len(chunk.page_content),\n",
        "                # Estimate line numbers (assuming ~80 chars per line)\n",
        "                'estimated_start_line': (i * (self.text_splitter._chunk_size - self.text_splitter._chunk_overlap)) // 80,\n",
        "                # Add preview of chunk for debugging\n",
        "                'preview': chunk.page_content[:100] + \"...\" if len(chunk.page_content) > 100 else chunk.page_content\n",
        "            })\n",
        "\n",
        "        # Create vector store with embedded chunks\n",
        "        # ChromaDB handles the embedding and storage automatically\n",
        "        print(\"üßÆ Creating embeddings and initializing vector store...\")\n",
        "\n",
        "        try:\n",
        "            # Create new vector store (overwrites if exists)\n",
        "            self.vector_store = Chroma.from_documents(\n",
        "                documents=chunks,\n",
        "                embedding=self.embeddings,\n",
        "                collection_name=\"api_docs\",\n",
        "                # Configure ChromaDB for optimal performance\n",
        "                collection_metadata={\n",
        "                    \"hnsw:space\": \"cosine\",  # Use cosine similarity\n",
        "                    \"hnsw:construction_ef\": 200,  # Higher = better quality, slower\n",
        "                    \"hnsw:M\": 16  # Higher = more connections, better recall\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Store processed documents for reference\n",
        "            self.processed_docs = chunks\n",
        "\n",
        "            print(f\"‚úÖ Vector store ready with {len(chunks)} embedded chunks\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error creating vector store: {e}\")\n",
        "            raise\n",
        "\n",
        "        return self.vector_store\n",
        "\n",
        "    def retrieve_relevant_chunks(self, query: str, k: int = 10, score_threshold: float = 0.0) -> List[Document]:\n",
        "        \"\"\"\n",
        "        Retrieve the most relevant documentation chunks for a query.\n",
        "\n",
        "        Args:\n",
        "            query (str): The user's question/search query\n",
        "            k (int): Number of chunks to retrieve (default: 10)\n",
        "            score_threshold (float): Minimum similarity score (0-1) to include results\n",
        "\n",
        "        Returns:\n",
        "            List[Document]: Relevant chunks ordered by similarity score\n",
        "\n",
        "        This method:\n",
        "        1. Embeds the query using the same model as the documents\n",
        "        2. Performs similarity search in the vector space\n",
        "        3. Returns the k most similar chunks\n",
        "        4. Optionally filters by similarity threshold\n",
        "        \"\"\"\n",
        "        if not self.vector_store:\n",
        "            print(\"‚ö†Ô∏è  No vector store available. Process documentation first.\")\n",
        "            return []\n",
        "\n",
        "        print(f\"üîç Retrieving {k} most relevant chunks for query: '{query[:50]}...'\")\n",
        "\n",
        "        try:\n",
        "            # Perform similarity search\n",
        "            # ChromaDB handles query embedding automatically\n",
        "            relevant_chunks = self.vector_store.similarity_search_with_score(\n",
        "                query=query,\n",
        "                k=k  # Get k most similar chunks\n",
        "            )\n",
        "\n",
        "            # Filter by score threshold if specified\n",
        "            if score_threshold > 0:\n",
        "                # Note: ChromaDB returns distance, not similarity\n",
        "                # Lower distance = higher similarity\n",
        "                relevant_chunks = [\n",
        "                    (doc, score) for doc, score in relevant_chunks\n",
        "                    if score <= (1 - score_threshold)  # Convert to distance threshold\n",
        "                ]\n",
        "\n",
        "            # Extract just the documents (remove scores for now)\n",
        "            chunks = [doc for doc, score in relevant_chunks]\n",
        "\n",
        "            print(f\"‚úÖ Retrieved {len(chunks)} relevant chunks\")\n",
        "\n",
        "            # Add retrieval metadata for debugging\n",
        "            for i, (chunk, score) in enumerate(zip(chunks, [s for _, s in relevant_chunks])):\n",
        "                chunk.metadata['retrieval_rank'] = i + 1\n",
        "                chunk.metadata['retrieval_score'] = f\"{1 - score:.3f}\"  # Convert to similarity\n",
        "\n",
        "            return chunks\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error retrieving chunks: {e}\")\n",
        "            return []\n",
        "\n",
        "    def get_statistics(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get statistics about the processed documentation.\n",
        "\n",
        "        Returns:\n",
        "            Dict with statistics about chunks, tokens, etc.\n",
        "        \"\"\"\n",
        "        if not self.processed_docs:\n",
        "            return {\"status\": \"No documents processed\"}\n",
        "\n",
        "        total_chars = sum(len(chunk.page_content) for chunk in self.processed_docs)\n",
        "\n",
        "        return {\n",
        "            \"total_chunks\": len(self.processed_docs),\n",
        "            \"total_characters\": total_chars,\n",
        "            \"estimated_tokens\": total_chars // 4,\n",
        "            \"average_chunk_size\": total_chars // len(self.processed_docs) if self.processed_docs else 0,\n",
        "            \"source_url\": self.processed_docs[0].metadata.get('source', 'Unknown') if self.processed_docs else None\n",
        "        }"
      ],
      "metadata": {
        "id": "YZgz1WQ8gMsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üßë‚Äçüíª Code Generator Agent\n",
        "\n",
        "The `CodeGeneratorAgent` is responsible for:\n",
        "\n",
        "- üõ†Ô∏è **Generating executable code** tailored to the user‚Äôs query  \n",
        "- üìö **Using documentation chunks** retrieved by the RAG processor  \n",
        "- ü§ñ **Leveraging LLMs (e.g., GPT-3.5/4)** to synthesize practical, working code snippets\n"
      ],
      "metadata": {
        "id": "QBi6k_VIgZRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CodeGeneratorAgent:\n",
        "    \"\"\"\n",
        "    Generates executable code based on documentation chunks.\n",
        "\n",
        "    This agent is a specialized LLM that:\n",
        "    1. Analyzes retrieved documentation chunks\n",
        "    2. Understands the user's specific requirements\n",
        "    3. Generates clean, working code that solves the problem\n",
        "    4. Includes proper imports, error handling, and best practices\n",
        "\n",
        "    The agent uses careful prompt engineering to ensure high-quality output.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"gpt-3.5-turbo\", temperature: float = 0.1):\n",
        "        \"\"\"\n",
        "        Initialize the code generator with an LLM.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): OpenAI model to use (gpt-3.5-turbo or gpt-4)\n",
        "            temperature (float): Controls randomness (0=deterministic, 1=creative)\n",
        "                               We use low temperature for consistent code generation\n",
        "        \"\"\"\n",
        "        # Initialize the language model\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=model_name,\n",
        "            temperature=temperature,  # Low temperature for consistent code\n",
        "            max_tokens=2000,  # Generous token limit for complex code\n",
        "            model_kwargs={\n",
        "                \"top_p\": 0.95,  # Nucleus sampling for quality\n",
        "                \"frequency_penalty\": 0.0,  # Don't penalize repetition in code\n",
        "                \"presence_penalty\": 0.0  # Don't force topic changes\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Create a sophisticated prompt template\n",
        "        # This prompt is carefully crafted to generate high-quality code\n",
        "        self.prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are an expert programmer with deep knowledge of {tool_name}.\n",
        "Your task is to generate clean, executable code based on official documentation.\n",
        "\n",
        "DOCUMENTATION CHUNKS:\n",
        "{documentation}\n",
        "\n",
        "USER QUESTION: {question}\n",
        "\n",
        "REQUIREMENTS:\n",
        "1. Generate ONLY the code needed to answer the question\n",
        "2. Include ALL necessary imports at the top\n",
        "3. Use descriptive variable names and follow conventions\n",
        "4. Add brief inline comments for clarity\n",
        "5. Include basic error handling where appropriate\n",
        "6. Make the code production-ready and efficient\n",
        "7. If the documentation shows examples, adapt them to fit the question\n",
        "8. If multiple approaches exist, choose the most modern/recommended one\n",
        "\n",
        "IMPORTANT:\n",
        "- Base your code strictly on the provided documentation\n",
        "- Do not make assumptions beyond what's documented\n",
        "- If something is unclear, use the most common approach\n",
        "- Ensure the code is complete and runnable\n",
        "\n",
        "Generate the code below:\n",
        "```python\n",
        "\"\"\")\n",
        "\n",
        "        # Create the LLM chain\n",
        "        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)\n",
        "\n",
        "        # Track generation history for debugging\n",
        "        self.generation_history = []\n",
        "\n",
        "    def generate_code(self, question: str, doc_chunks: List[Document], tool_name: str = \"the tool\") -> str:\n",
        "        \"\"\"\n",
        "        Generate code based on documentation chunks and user question.\n",
        "\n",
        "        Args:\n",
        "            question (str): The user's specific question/requirement\n",
        "            doc_chunks (List[Document]): Retrieved documentation chunks\n",
        "            tool_name (str): Name of the tool/library for context\n",
        "\n",
        "        Returns:\n",
        "            str: Generated code ready for execution\n",
        "\n",
        "        The method:\n",
        "        1. Formats documentation chunks for the prompt\n",
        "        2. Injects all context into the prompt template\n",
        "        3. Calls the LLM to generate code\n",
        "        4. Cleans and validates the output\n",
        "        \"\"\"\n",
        "        print(f\"üíª Generating code for: '{question}'\")\n",
        "\n",
        "        # Format documentation chunks for the prompt\n",
        "        # We include chunk numbers for potential citations\n",
        "        formatted_docs = []\n",
        "\n",
        "        for i, chunk in enumerate(doc_chunks):\n",
        "            # Include metadata for context\n",
        "            chunk_header = f\"[Chunk {i+1} - {chunk.metadata.get('chunk_index', 'Unknown')}]\"\n",
        "\n",
        "            # Include the actual content\n",
        "            chunk_content = chunk.page_content.strip()\n",
        "\n",
        "            # Combine with clear separation\n",
        "            formatted_chunk = f\"{chunk_header}\\n{chunk_content}\"\n",
        "            formatted_docs.append(formatted_chunk)\n",
        "\n",
        "        # Join all chunks with clear separators\n",
        "        documentation_text = \"\\n\\n---\\n\\n\".join(formatted_docs)\n",
        "\n",
        "        # Log what we're sending (for debugging)\n",
        "        print(f\"üìö Using {len(doc_chunks)} documentation chunks\")\n",
        "        print(f\"üìù Total documentation length: {len(documentation_text)} characters\")\n",
        "\n",
        "        try:\n",
        "            # Generate code using the LLM chain\n",
        "            response = self.chain.run(\n",
        "                documentation=documentation_text,\n",
        "                question=question,\n",
        "                tool_name=tool_name\n",
        "            )\n",
        "\n",
        "            # Clean the response\n",
        "            # Remove markdown code blocks if present\n",
        "            code = response.strip()\n",
        "            if code.startswith(\"```python\"):\n",
        "                code = code[9:]  # Remove ```python\n",
        "            if code.startswith(\"```\"):\n",
        "                code = code[3:]  # Remove ```\n",
        "            if code.endswith(\"```\"):\n",
        "                code = code[:-3]  # Remove trailing ```\n",
        "\n",
        "            # Final cleanup\n",
        "            code = code.strip()\n",
        "\n",
        "            # Store in history\n",
        "            self.generation_history.append({\n",
        "                \"question\": question,\n",
        "                \"code\": code,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"chunks_used\": len(doc_chunks)\n",
        "            })\n",
        "\n",
        "            print(\"‚úÖ Code generation complete\")\n",
        "\n",
        "            return code\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"# Error generating code: {str(e)}\\n# Please check the documentation and try again.\"\n",
        "            print(f\"‚ùå Generation error: {e}\")\n",
        "            return error_msg\n",
        "\n",
        "    def validate_code(self, code: str) -> Tuple[bool, List[str]]:\n",
        "        \"\"\"\n",
        "        Basic validation of generated code.\n",
        "\n",
        "        Args:\n",
        "            code (str): Generated code to validate\n",
        "\n",
        "        Returns:\n",
        "            Tuple[bool, List[str]]: (is_valid, list_of_issues)\n",
        "        \"\"\"\n",
        "        issues = []\n",
        "\n",
        "        # Check for common issues\n",
        "        if not code.strip():\n",
        "            issues.append(\"Code is empty\")\n",
        "\n",
        "        if \"import\" not in code and len(code) > 50:\n",
        "            issues.append(\"No imports found (might be incomplete)\")\n",
        "\n",
        "        if code.count(\"(\") != code.count(\")\"):\n",
        "            issues.append(\"Mismatched parentheses\")\n",
        "\n",
        "        if code.count(\"[\") != code.count(\"]\"):\n",
        "            issues.append(\"Mismatched square brackets\")\n",
        "\n",
        "        if code.count(\"{\") != code.count(\"}\"):\n",
        "            issues.append(\"Mismatched curly braces\")\n",
        "\n",
        "        if \"TODO\" in code or \"FIXME\" in code:\n",
        "            issues.append(\"Contains TODO/FIXME markers\")\n",
        "\n",
        "        return len(issues) == 0, issues"
      ],
      "metadata": {
        "id": "jH_t-yw_gWDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üí¨ Explanation Agent\n",
        "\n",
        "The `ExplanationAgent` is responsible for:\n",
        "\n",
        "- üßæ **Generating clear, human-friendly explanations** of the generated code  \n",
        "- üîç **Referencing relevant documentation** to justify and clarify the code logic  \n",
        "- üìå **Providing inline citations** to help users understand where each concept comes from\n"
      ],
      "metadata": {
        "id": "JB0i6MyMgpmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExplanationAgent:\n",
        "    \"\"\"\n",
        "    Explains generated code with references to documentation.\n",
        "\n",
        "    This agent creates human-friendly explanations that:\n",
        "    1. Break down what the code does step-by-step\n",
        "    2. Reference specific documentation chunks\n",
        "    3. Highlight important concepts and best practices\n",
        "    4. Provide context for design decisions\n",
        "\n",
        "    The explanations are designed to be educational and help users\n",
        "    understand not just what the code does, but why it works.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"gpt-3.5-turbo\", temperature: float = 0.3):\n",
        "        \"\"\"\n",
        "        Initialize the explanation agent.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): OpenAI model to use\n",
        "            temperature (float): Slightly higher than code gen for more natural language\n",
        "        \"\"\"\n",
        "        # Initialize the language model with balanced settings\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=model_name,\n",
        "            temperature=temperature,  # Bit more creative for explanations\n",
        "            max_tokens=1500,  # Good length for detailed explanations\n",
        "            model_kwargs={\n",
        "                \"top_p\": 0.95,\n",
        "                \"frequency_penalty\": 0.1,  # Slight penalty to reduce repetition\n",
        "                \"presence_penalty\": 0.1    # Encourage covering all aspects\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Create an explanation-focused prompt\n",
        "        self.prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a technical educator explaining code to developers.\n",
        "Your goal is to create clear, insightful explanations that help users understand both the code and the underlying concepts.\n",
        "\n",
        "CODE TO EXPLAIN:\n",
        "```python\n",
        "{code}\n",
        "```\n",
        "\n",
        "DOCUMENTATION CHUNKS:\n",
        "{documentation}\n",
        "\n",
        "EXPLANATION:\n",
        "\"\"\")\n",
        "\n",
        "        # Create the LLM chain\n",
        "        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)"
      ],
      "metadata": {
        "id": "dXwvMO9iga-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üèõÔ∏è 3. Main Orchestration Pipeline\n",
        "\n",
        "Now we'll create the main orchestrator class: **`RAGAPIAssistant`**.  \n",
        "This class manages the entire end-to-end workflow:\n",
        "\n",
        "1. üåê **Web Search** using `DocumentationCrawler`  \n",
        "2. üß† **Chunking & Retrieval** with `RAGDocumentProcessor`  \n",
        "3. üßë‚Äçüíª **Code Generation** via `CodeGeneratorAgent`  \n",
        "4. üí¨ **Explanation Synthesis** using `ExplanationAgent`  \n",
        "\n",
        "It coordinates all components to produce a seamless experience from question to runnable solution.\n",
        "\n",
        "---\n",
        "\n",
        "## üé® Display & Formatting Utilities\n",
        "\n",
        "Let‚Äôs define helper functions to render outputs cleanly within the notebook:\n",
        "\n",
        "- üìÑ **Markdown rendering** for text explanations  \n",
        "- üßæ **HTML tables** for structured results  \n",
        "- üí° **Syntax-highlighted code blocks** for generated scripts  \n",
        "\n",
        "These utilities use `IPython.display` to enhance notebook readability.\n"
      ],
      "metadata": {
        "id": "wV255lOBh0tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_search_results(results: List[Dict], tool_name: str):\n",
        "    \"\"\"Displays the web search results panel.\"\"\"\n",
        "    if not results:\n",
        "        not_found_message = f\"‚ùå **Documentation Not Found**\\n\\nCould not find official documentation for **{tool_name}**. Please check the tool name or try a more specific query.\"\n",
        "        display(Markdown(not_found_message))\n",
        "        return\n",
        "\n",
        "    top_result = results[0]\n",
        "    result_html = f\"\"\"\n",
        "    <div style=\"border: 1px solid #ddd; border-radius: 8px; padding: 16px; margin-bottom: 16px;\">\n",
        "        <h3 style=\"margin-top: 0;\">üåê Documentation Found</h3>\n",
        "        <p><strong>Tool:</strong> {tool_name}</p>\n",
        "        <p><strong>URL:</strong> <a href=\"{top_result['url']}\" target=\"_blank\">{top_result['url']}</a></p>\n",
        "        <p><strong>Title:</strong> {top_result['title']}</p>\n",
        "        <p><strong>Snippet:</strong> <em>{top_result['snippet']}</em></p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(result_html))\n",
        "\n",
        "def display_retrieved_chunks(chunks: List[Document]):\n",
        "    \"\"\"Displays the retrieved documentation snippets in a pretty table.\"\"\"\n",
        "    if not chunks:\n",
        "        display(Markdown(\"No relevant chunks were retrieved from the documentation.\"))\n",
        "        return\n",
        "\n",
        "    display(Markdown(\"---\"))\n",
        "    display(Markdown(\"### üìö Retrieved Snippets\"))\n",
        "    display(Markdown(\"These are the most relevant passages from the documentation used to generate the code.\"))\n",
        "\n",
        "    # Create a DataFrame for prettier display\n",
        "    data = []\n",
        "    for chunk in chunks:\n",
        "        data.append({\n",
        "            \"Rank\": chunk.metadata.get('retrieval_rank', 'N/A'),\n",
        "            \"Similarity\": chunk.metadata.get('retrieval_score', 'N/A'),\n",
        "            \"Chunk Index\": chunk.metadata.get('chunk_index', 'N/A'),\n",
        "            \"Content Preview\": chunk.page_content[:250] + \"...\" # Truncate for display\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    # Use pandas styling for better table rendering in Colab\n",
        "    styled_df = df.style.set_properties(**{\n",
        "        'text-align': 'left',\n",
        "        'white-space': 'pre-wrap',\n",
        "        'font-size': '12px'\n",
        "    }).set_table_styles([\n",
        "        {'selector': 'th', 'props': [('text-align', 'left'), ('font-weight', 'bold')]}\n",
        "    ]).hide(axis=\"index\") # Hide the default pandas index\n",
        "\n",
        "    display(styled_df)\n",
        "\n",
        "\n",
        "def display_generated_code(code: str, validation_issues: List[str]):\n",
        "    \"\"\"Displays the generated code with syntax highlighting and validation warnings.\"\"\"\n",
        "    display(Markdown(\"---\"))\n",
        "    display(Markdown(\"### üßë‚Äçüíª Generated Code\"))\n",
        "    display(Markdown(\"Here is the runnable Python code generated based on the documentation.\"))\n",
        "\n",
        "    if validation_issues:\n",
        "        warning_message = \"‚ö†Ô∏è **Validation Warnings:**\\n\" + \"\\n\".join([f\"- {issue}\" for issue in validation_issues])\n",
        "        display(Markdown(warning_message))\n",
        "\n",
        "    display(Code(code, language='python'))\n",
        "\n",
        "def display_explanation(explanation: str):\n",
        "    \"\"\"Displays the final, human-friendly explanation.\"\"\"\n",
        "    display(Markdown(\"---\"))\n",
        "    display(Markdown(\"### üí¨ Explanation\"))\n",
        "    display(Markdown(\"Below is a step-by-step walkthrough of the code, with citations from the documentation.\"))\n",
        "    display(Markdown(explanation))"
      ],
      "metadata": {
        "id": "_4sH0BhSgqtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### üß† Updating the Explanation Agent\n",
        "\n",
        "To ensure explanations include **citations** back to the **source documentation**, we‚Äôll:\n",
        "\n",
        "- ‚úçÔ∏è **Update the prompt** used by the `ExplanationAgent`  \n",
        "- üßº **Wrap the logic** inside a clean `generate_explanation()` method  \n",
        "\n",
        "This aligns its interface and behavior with the `CodeGeneratorAgent` for consistency and modularity.\n"
      ],
      "metadata": {
        "id": "Rvvm3kvmh5YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExplanationAgent:\n",
        "    \"\"\"\n",
        "    Explains generated code with references to documentation.\n",
        "    (Updated version with better prompting and a dedicated method)\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name: str = \"gpt-3.5-turbo\", temperature: float = 0.3):\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=model_name,\n",
        "            temperature=temperature,\n",
        "            max_tokens=1500,\n",
        "            model_kwargs={\"top_p\": 0.95}\n",
        "        )\n",
        "\n",
        "        # Enhanced prompt to enforce citations and clear structure\n",
        "        self.prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a helpful technical writer and expert programmer.\n",
        "Your goal is to explain the provided code clearly, referencing the documentation chunks for justification.\n",
        "\n",
        "USER QUESTION: \"{question}\"\n",
        "\n",
        "DOCUMENTATION CONTEXT:\n",
        "{documentation}\n",
        "\n",
        "CODE TO EXPLAIN:\n",
        "```python\n",
        "{code}\n",
        "\n",
        "\n",
        "REQUIREMENTS\n",
        "\n",
        "Start with a high-level summary of what the code does.\n",
        "\n",
        "Provide a step-by-step explanation of the code logic.\n",
        "\n",
        "Explain why the code works by linking it to concepts from the documentation.\n",
        "\n",
        "Crucially, you must cite the most relevant documentation chunk(s) for each point\n",
        "\n",
        "using the format [Chunk N]\n",
        "\n",
        "Use Markdown for clear formatting (headings, lists, bold text).\n",
        "\n",
        "The tone should be educational, clear, and encouraging.\n",
        "\n",
        "EXPLANATION (in Markdown):\n",
        "\n",
        "\"\"\")\n",
        "        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)\n",
        "        self.explanation_history = []\n",
        "\n"
      ],
      "metadata": {
        "id": "XHXRpG7Fh16b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_explanation(self, code: str, doc_chunks: List[Document], question: str) -> str:\n",
        "    \"\"\"\n",
        "    Generates a human-friendly explanation of the code with citations.\n",
        "\n",
        "    Args:\n",
        "        code (str): The generated code to explain.\n",
        "        doc_chunks (List[Document]): The documentation chunks used as context.\n",
        "        question (str): The original user question.\n",
        "\n",
        "    Returns:\n",
        "        str: A Markdown-formatted explanation.\n",
        "    \"\"\"\n",
        "    print(\"üí¨ Generating explanation...\")\n",
        "\n",
        "    # Format documentation for the prompt, including chunk numbers\n",
        "    formatted_docs = []\n",
        "    for i, chunk in enumerate(doc_chunks):\n",
        "        chunk_header = f\"[Chunk {chunk.metadata.get('retrieval_rank', i+1)}]\"\n",
        "        chunk_content = chunk.page_content.strip()\n",
        "        formatted_docs.append(f\"{chunk_header}\\n{chunk_content}\")\n",
        "\n",
        "    documentation_text = \"\\n\\n---\\n\\n\".join(formatted_docs)\n",
        "\n",
        "    try:\n",
        "        # Run the LLM chain\n",
        "        explanation = self.chain.run(\n",
        "            code=code,\n",
        "            documentation=documentation_text,\n",
        "            question=question\n",
        "        )\n",
        "\n",
        "        self.explanation_history.append({\n",
        "            \"question\": question,\n",
        "            \"explanation\": explanation,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        })\n",
        "\n",
        "        print(\"‚úÖ Explanation generated successfully.\")\n",
        "        return explanation.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"### Error Generating Explanation\\n\\nAn error occurred: {str(e)}\"\n",
        "        print(f\"‚ùå Explanation error: {e}\")\n",
        "        return error_msg"
      ],
      "metadata": {
        "id": "h7GycoaqjDeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### üèóÔ∏è The `RAGAPIAssistant` Orchestrator\n",
        "\n",
        "This is the central class that connects all the pieces.  \n",
        "It takes a **tool name** and a **user question**, then executes the full RAG pipeline:\n",
        "\n",
        "1. üîç Searches for relevant documentation  \n",
        "2. üß† Ingests and indexes it in a vector store  \n",
        "3. üìö Retrieves the most relevant chunks  \n",
        "4. üßë‚Äçüíª Generates executable code  \n",
        "5. üí¨ Explains the code with source citations"
      ],
      "metadata": {
        "id": "JxZckICLjZO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGAPIAssistant:\n",
        "    \"\"\"\n",
        "    Orchestrates the entire RAG pipeline for answering API questions.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"Initializes all the necessary components.\"\"\"\n",
        "        print(\"üöÄ Initializing RAG API Assistant...\")\n",
        "        self.crawler = DocumentationCrawler()\n",
        "        self.rag_processor = RAGDocumentProcessor()\n",
        "        self.code_agent = CodeGeneratorAgent()\n",
        "        self.explanation_agent = ExplanationAgent()  # Updated version\n",
        "        print(\"‚úÖ Assistant is ready.\")\n",
        "\n",
        "    def answer_question(self, tool_name: str, question: str, max_search_results: int = 3, max_retrieved_chunks: int = 10):\n",
        "        \"\"\"\n",
        "        Executes the full pipeline to answer a user's question.\n",
        "\n",
        "        Args:\n",
        "            tool_name (str): The name of the library/tool (e.g., \"pandas\").\n",
        "            question (str): The user's question (e.g., \"how to merge two dataframes\").\n",
        "            max_search_results (int): Number of web search results to consider.\n",
        "            max_retrieved_chunks (int): Number of documentation chunks to retrieve.\n",
        "        \"\"\"\n",
        "        # --- 1. Documentation Hunt ---\n",
        "        search_results = self.crawler.search_documentation(tool_name, max_results=max_search_results)\n",
        "        display_search_results(search_results, tool_name)\n",
        "\n",
        "        if not search_results:\n",
        "            return  # Stop if no documentation was found\n",
        "\n",
        "        # --- 2. RAG Ingestion ---\n",
        "        doc_url = search_results[0]['url']\n",
        "        content, success = self.crawler.fetch_page_content(doc_url)\n",
        "\n",
        "        if not success:\n",
        "            display(Markdown(f\"‚ùå **Failed to fetch content from {doc_url}**\"))\n",
        "            return\n",
        "\n",
        "        vector_store = self.rag_processor.process_documentation(content, source_url=doc_url)\n",
        "\n",
        "        # --- 3. Targeted Retrieval ---\n",
        "        retrieved_chunks = self.rag_processor.retrieve_relevant_chunks(question, k=max_retrieved_chunks)\n",
        "        display_retrieved_chunks(retrieved_chunks)\n",
        "\n",
        "        if not retrieved_chunks:\n",
        "            return  # Stop if no relevant context is found\n",
        "\n",
        "        # --- 4. Code Generation ---\n",
        "        generated_code = self.code_agent.generate_code(question, retrieved_chunks, tool_name)\n",
        "        is_valid, issues = self.code_agent.validate_code(generated_code)\n",
        "        display_generated_code(generated_code, issues)\n",
        "\n",
        "        # --- 5. Explanation ---\n",
        "        explanation = self.explanation_agent.generate_explanation(generated_code, retrieved_chunks, question)\n",
        "        display_explanation(explanation)\n"
      ],
      "metadata": {
        "id": "zGD1GlhJjT4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üöÄ 4. Demonstration: Running the Assistant\n",
        "\n",
        "Now it's time to see the system **in action**!  \n",
        "We‚Äôll define the tool and question, instantiate the assistant, and let it walk through the full pipeline.\n",
        "\n",
        "### üß™ Example Scenario\n",
        "\n",
        "We‚Äôll ask a common question about the popular **`requests`** library:"
      ],
      "metadata": {
        "id": "dAzA8Z3mjg-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- INTERACTIVE RUN ---\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def get_non_empty(prompt, default=None):\n",
        "    raw = input(f\"{prompt}\" + (f\" [{default}]\" if default else \"\") + \": \").strip()\n",
        "    if not raw and default is not None:\n",
        "        return default\n",
        "    while not raw:\n",
        "        raw = input(f\"{prompt} (cannot be empty): \").strip()\n",
        "    return raw\n",
        "\n",
        "tool = get_non_empty(\"Enter tool/library name\", default=\"requests\")\n",
        "question = get_non_empty(\n",
        "    \"Enter your question (e.g., how do I send a POST request with a JSON payload and check for errors?)\",\n",
        "    default=\"How do I send a POST request with a JSON payload and check for errors?\"\n",
        ")\n",
        "\n",
        "clear_output(wait=True)\n",
        "# --- HARDCODED EXAMPLE ---\n",
        "assistant = RAGAPIAssistant()\n",
        "tool_name = \"requests\"\n",
        "question = (\n",
        "    'How do I send a POST request to https://httpbin.org/post with JSON payload '\n",
        "    '{\"name\":\"Ido\"}, include the header \"Content-Type: application/json\", raise an '\n",
        "    'exception if the response status is not 2xx, and print the returned JSON?'\n",
        ")\n",
        "assistant.answer_question(tool_name=tool_name, question=question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "kq9bqyr9h62r",
        "outputId": "36bb3873-1669-4d0f-b5d9-d549b9d374ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Initializing RAG API Assistant...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3039025726.py:17: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  self.ddgs = DDGS()  # DuckDuckGo search instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Assistant is ready.\n",
            "üîç Searching for: requests official documentation API reference site:*.org OR site:*.io OR site:*.com\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "‚ùå **Documentation Not Found**\n\nCould not find official documentation for **requests**. Please check the tool name or try a more specific query."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üèÅ 5. Conclusion & Future Enhancements\n",
        "\n",
        "This notebook showcases a complete, end-to-end **RAG pipeline** that intelligently:\n",
        "\n",
        "- üåê Crawls the web for documentation  \n",
        "- üì• Ingests and stores it with semantic embeddings  \n",
        "- üîç Retrieves the most relevant chunks  \n",
        "- üßë‚Äçüíª Generates executable code  \n",
        "- üí¨ Explains it with human-friendly, cited descriptions  \n",
        "\n",
        "By orchestrating these components, we've built a powerful assistant capable of answering technical questions with **accuracy and context**.\n",
        "\n",
        "---\n",
        "\n",
        "### üîÆ Future Enhancements\n",
        "\n",
        "This project lays a solid foundation. Here are several ways to extend it further:\n",
        "\n",
        "- üîó **Multi-Page Crawling**  \n",
        "  Extend the `DocumentationCrawler` to follow links within a documentation site and build a richer multi-page knowledge base.\n",
        "\n",
        "- ‚ö° **Caching Mechanism**  \n",
        "  Cache fetched documentation and generated embeddings to reduce latency and OpenAI API usage for repeated queries.\n",
        "\n",
        "- üß† **Advanced Model Support**  \n",
        "  Upgrade from `gpt-3.5-turbo` to `gpt-4` or `gpt-4o` for improved code quality and more insightful explanations.\n",
        "\n",
        "- üñ•Ô∏è **Interactive UI**  \n",
        "  Wrap the assistant in a user-friendly web interface using tools like **Streamlit** or **Gradio**.\n",
        "\n",
        "- üëç **Feedback Loop**  \n",
        "  Let users rate code and explanations. Use that feedback to iteratively fine-tune prompts or adjust model behavior.\n",
        "\n",
        "- üß© **Code Block Preservation**  \n",
        "  Improve `fetch_page_content` to preserve `<code>` and `<pre>` blocks from HTML pages‚Äîthese often contain essential examples.\n"
      ],
      "metadata": {
        "id": "mbz6G5oVjolA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rSx7UucLjh-a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}